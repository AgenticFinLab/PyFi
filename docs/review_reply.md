# Official Review of Submission2619 by Reviewer 7Uxq (Confidence: 4, Overall Assessment: 2.5)

Summary Of Strengths:
1.Well-motivated task decomposition. The pyramid + question-chain design maps naturally to real financial analysis workflows and supports fine-grained error diagnosis across skill levels.
2.Large-scale, structured dataset. PyFi-600K is sizable and includes multi-topic/chart coverage with additional context fields, enabling both benchmarking and training.
3.Attention to data leakage. The paper explicitly defines and tests leakage with image-removed controls and filters the test set accordingly, showing awareness of multimodal evaluation pitfalls.

Summary Of Weaknesses:
1.Evaluation set becomes small after leakage filtering. Reducing the test set (e.g., to ~301 from 1000) may hurt statistical reliability and representativeness. Provide distribution checks, confidence intervals, or repeated sampling to support robustness.

Reply:

2.Synthetic bias in answer options. The paper reports strong option-position imbalance. A small rebalancing experiment helps, but the generation process itself likely needs constraints to prevent shortcut learning.

Reply:

3.Complex pipeline and compute cost. The MCTS + multi-agent setup is elaborate and may be expensive and sensitive to randomness; more concrete cost/throughput and reproducibility details would strengthen the contribution.

Reply:

4.Potential shortcut via auxiliary text fields. If “background/context analysis” text is available at inference, models may rely on generated hints rather than genuine visual understanding. The paper should clearly separate “image-only” vs “image+aux text” settings and discuss intended use.

Reply:

Confidence: 4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.
Soundness: 3 = Acceptable: This study provides sufficient support for its main claims. Some minor points may need extra support or details.
Excitement: 3 = Interesting: I might mention some points of this paper to others and/or attend its presentation in a conference if there's time.
Overall Assessment: 2.5 = Borderline Findings
Reproducibility: 4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.
Datasets: 3 = Potentially useful: Someone might find the new datasets useful for their work.





# Official Review of Submission2619 by Reviewer r7ew (Confidence: 3, Overall Assessment: 2.5)

Summary Of Strengths:
1.This paper introduces a dataset with approximately 600,000 samples, surpassing the traditional manually annotated datasets, providing a benchmark for subsequent related research in the field of financial image understanding.
2.The PyFi framework has good scalability. It offers an economical and efficient data generation solution that does not rely on manual annotation. They propose a data generation based on intelligent agent.
3.The logic of the proposed methodology is coherent. Additionally, the visualization presentation quality is fine.

Summary Of Weaknesses:
1.The author points out that the existing pre-training model's data generation method may contain factual errors or illusions. The author's data generation method (the PyFi-adv mechanism) also relies on pre-trained VLMs. The author relies on MCTS to ensure quality, and the logic is to propagate the comparison between the top-level problem answer and the actual data backward to individual samples in the chain. However, the author does not provide detailed verification methods or further experiments (such as manual verification) to prove that it can alleviate the illusion problem of the samples generated by the PyFi-adv mechanism.

Reply:

2.There is a lack of benchmark tests. The author did not compare with other automated data generation methods. The author should add comparative experiments with existing automated data generation methods to verify the effectiveness of the author's work.

Reply:

3.The ablation experiments of the methodological contribution are insufficient. The author significantly improved the performance of the Qwen model by fine-tuning on the PyFi-600K dataset. However, due to the large scale of this dataset, the experimental results currently cannot distinguish whether the performance improvement is due to the innovative hierarchical sample chain structure or simply benefiting from the coverage of large-scale financial domain data. The paper lacks key ablation experiments to decouple the impact of data size and sample structure.

Reply:

4.There are some typos in the text, such as citation breaks, incorrect table citations, etc. The author should proofread. In line 41, there is an unknown question mark in the sentence “step-wise annotations (?Zhang et al., 2024b; Qi et al., 2024),…” In line 349, the chart reference number is incorrect. It seems that the author intended to refer to Table 1, because Table 3 is in the appendix and the content does not match. Moreover, clicking on the reference led to Figure 3, which indicates a reference error.
Reply:

Confidence: 3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.
Soundness: 2.5
Excitement: 2.5
Overall Assessment: 2.5 = Borderline Findings
Reproducibility: 3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.
Datasets: 1 = No usable datasets submitted.
Software: 1 = No usable software released.




# Official Review of Submission2619 by Reviewer BSq5 (Confidence: 3, Overall Assessment: 3)

Summary Of Strengths:
1.A large-scale pyramid-like financial image understanding dataset spanning six difficulty levels
2.A well-designed data construction framework featuring a challenger agent that competes with a solver agent under the MCTS paradigm to generate question chains that progressively probe deeper capability levels
3.Comprehensive benchmark
4.Verify improvement through fine-tuning on the domain-specific dataset

Summary Of Weaknesses:
1.Requires human verification of the synthetic dataset quality (a subset)

Reply:

2.If tuning on general-domain chart understanding datasets, how well do they generalize to the financial domain?

Reply:

3.More discussion about the benefits of the main contribution—the proposed data construction framework—would be helpful. Consider adding ablations or case comparisons.

Reply:

Confidence: 3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.
Soundness: 3.5
Excitement: 3 = Interesting: I might mention some points of this paper to others and/or attend its presentation in a conference if there's time.
Overall Assessment: 3 = Findings: I think this paper could be accepted to the Findings of the ACL.
Reproducibility: 4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.
Datasets: 4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.
Software: 4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work.



# Official Review of Submission2619 by Reviewer o6Jh (Confidence: 2, Overall Assessment: 2)

Summary Of Strengths:
1.This paper proposed an interesting financial understanding task. The idea of building a pyramid structure of QAs is interesting and insightful for benchmark reasoning, which might be generalized to more domains. The proposed benchmark is challenging so that the VLMs cannot address well, which provides insightful directions.

Summary Of Weaknesses:

### I. The generation mechanism is still based on VLMs, which means hallucinations persist. Moreover, the generation of the top level is conditioned on samples from lower layers, so hallucinations in lower-layer samples can lead to errors in the top-layer samples.

**Reply**: 
This is precisely where the superiority and unique design of our mechanism lie, giving our method its innovative value:  
(1) As described in Section 4 and Figure 4: "PyFi-600K enables us to trace the problem-solving chain from Decision Support (DS) to Logical Reasoning (LR) and eventually to Perception (PP), thereby diagnosing how an error at one level leads to the final mistake. Such a tracing-back approach is crucial for understanding the limitations of VLMs in financial decision-making, as it reveals at which capability level a failure occurs." Based on this, error analysis shows that model failures primarily stem from insufficient Calculation Analysis (CA) capability, rather than hallucination propagation. By tracing back through the question chain, the source of errors can be precisely identified, which demonstrates the controllability of the hierarchical structure.  
(2) As described in Sections 3.2 and 4, only when the top-level question is answered correctly will the other questions in the chain receive rewards. This reward reflects the accuracy of the lower-level questions and answers.  
(3) As described in Sections 3.1 and 4, after the entire generation process is completed, each sample has an independent reward (r ∈ [0,1]), allowing low-quality samples to be filtered out. In fact, during subsequent evaluations and dataset usage, we only selected data with r=1, meaning the question-answer pairs we use aim to avoid hallucination issues as much as possible.

Thus, hierarchical generation naturally offers greater benefits for generating more reliable data and improving data interpretability. This allows us to precisely identify which questions lead to errors in the final top-level questions. Those top-level questions answered incorrectly (some of which are caused by accumulated errors and hallucinations from lower-level questions) are not adopted. In other words, the dataset we use for evaluation minimizes hallucination issues to the greatest extent possible.

This conclusion is also supported by experimental results. Our empirical results demonstrate that models fine-tuned on PyFi-600K achieve a 19.52% accuracy improvement (Qwen2.5-VL-3B) and an 8.06% improvement (Qwen2.5-VL-7B) on the evaluation set. If hallucination propagation were a dominant issue, we would observe performance degradation or inconsistency across capability levels, rather than systematic improvements.

In summary, PyFi-adv's adversarial architecture, MCTS-based reward backpropagation, and step-wise process supervision collectively mitigate error propagation to a manageable level. The significant performance gains observed in fine-tuning experiments empirically validate the dataset quality.
### II. More importantly, I would like to know what the actual VLMs are used for the solver and the challenger and what the prompts are for them. I am also not clear on how the solver that gives the response determines whether it is correct or incorrect, as no ground-truth is provided.

**Reply**:
In our current implementation of PyFi-adv, both the Challenger agent (ψ) and Solver agent (φ) are instantiated using Doubao-seed-1-6-flash-250828 (as mentioned in Appendix I, line 1953-1954: 'Our implementation, using Doubao-seed-1-6-flash-250828...'). This is a production-grade VLM with strong instruction-following capabilities. This model is the best overall in terms of performance, output format stability, convenience, cost, concurrency, and speed. The choice of using the same base VLM for both agents also ensures a balanced adversarial dynamic. If one agent were significantly more capable, the adversarial game would collapse.

Prompt for Challenger (It is returned as a function's output, with the content in {} being the input variables):
```
"""
    Core Task: 
    Given a final question, a corresponding image, and a series of existing information, generate a new question-answer pair so that by addressing the generated question, one can extend existing information with the correct answer such that the extended information progresses one reasoning step towards solving the given final question.

    
    1. Background Information:

    - Here are six capability levels of financial knowledge and image understanding:
      * level 1: Perception (identifying chart basic elements)
      * level 2: Data extraction (reading and reporting explicit values or facts directly shown in the chart)
      * level 3: Calculation analysis (computing metrics based on the chart)
      * level 4: Pattern recognition (identifying observable trends, comparisons, or groupings visible in the data)
      * level 5: Logical reasoning (deriving relationships based on the chart)
      * level 6: Decision support (making decisions involving financial knowledge)
      

      
    2. Image Description:
    Below is the information extracted from the contextual text surrounding the image's location within the financial document.
    - Contextual information (******xxxxxxx******):
    ******
    {image_background}
    ******

    3. The final question is as follows:
    {final_question}

    4. Existing information (None means empty):
    {current_qa_chain_content}

    5. Existing question-answer pairs (None means empty):
    {current_same_parent_qa_nodes}

    6. Core Requirements:
    - {capability_sentence}
    - The correct answer to the question can be integrated into the existing information, advancing the reasoning process by one step toward solving the final question.
    - Only reflect and examine one piece of information or one knowledge point of the financial image, or comprehensively examine from different angles based on the existing information.
    - Must not duplicate existing question-answer pairs.
    - Must be independent from existing information and existing question-answer pairs.
    - The question must be related to finance.
    - The question must be related to the image and it can't be answered without the image.
    - The question must be objective  (must be single-choice and there must be only one correct choice).
    - The answer to this question must be unambiguous and verifiable.
    - The language of all output content must strictly be limited to English.
    - The number of words in the question should be between 10-500.

    7. Output Format (JSON):
    {{
      "question": "",
      "options": {{"A": "", "B": "", "C": "", "D": "",...}},
      "capability": "",
      "complexity": ""
    }}
    
    Explaination of each field:
    question: The newly generated question.
    options: {{"A": "option1", "B": "option2", "C": "option3", "D": "option4",...}}, there must be at least 3 options.
    capability: select one of the 6 capabilities: ['Perception','Data_extraction','Calculation_analysis','Pattern_recognition','Logical_reasoning','Decision_support'].
    complexity: select one of the 5 complexity degrees: ['1','2','3','4','5'], where '5' represents the most complex degree and '1' represents the simplest degree. 
    

    8. Quality Control:
    - Must not duplicate or depend on existing questions.
    - Must be totally different from existing questions and existing information, and not just described in a different way.
    - Avoid subjective or ambiguous terms.
    - Must spell out acronyms and abbreviations everywhere in the output content.
    - Must relate to the image itself.

    Generate exactly one new, unique, independent question following these requirements strictly. Output only valid JSON matching the specified format."""

```

Prompt for Solver (It is also returned as a function's output, with the content in {} being the input variables):
```
"""Core Task: Given the Question and the corresponding image, please generate the answer based on the image and a series of existing information.
  
    1.Image Background (******xxxxxxx******):
    ******
    {image_background}
    ******
    
    2. Given Question:
    {target_question_node_information}
    
    3. Existing information (None means empty):
    {current_qa_chain_content}
    
    4. Core Requirements:
    - To ensure complete accuracy, the answer must be subjected to rigorous analysis and comprehensive thinking. 
    
    5. Rules:
    (1) Answer must be unambiguous (just the letter)
    (2) Must be objectively correct based on the image
    (3) Select a letter from the options to answer the given Question 

    6. Output Format (JSON):
    {{
      "answer": "A"
    }}
    
    7. Examples:
    If the answer is A, output:
    {{
      "answer": "A"
    }}
    If the answer is D, output:
    {{
      "answer": "D"
    }}
    
    Generate exactly and completely correct answer letter following the rules strictly. Output only valid JSON matching the specified format."""
```

We have strictly defined the output formats for both the Challenger and the Solver.

Correctness cannot be directly determined from the answer given by the Solver. We determine or update the reward for questions along the entire chain by judging whether the answer to the top-level question is correct (See Appendix I Algorithms). Specifically, if the answer to the top-level question is correct (the ground truth for the top-level question is determined by a majority vote among multiple powerful models), then all question-answer pairs in that chain will have a higher r-value (r ∈ [0,1]), indicating greater credibility and quality. After multiple rounds of adversarial competence enhancement, we only select those question-answer pairs with r=1 as our evaluation dataset and training samples. This approach allows us to obtain high-quality, reliable question-answer pair data while minimizing manual effort and time costs.

PyFi-adv does establish ground-truth for the final Level-6 question via majority voting across multiple LLM  (typically 5-7 independent generations). This consensus mechanism filters out idiosyncratic errors, providing a reliable reference point for backpropagation.

The correctness of intermediate samples is determined retroactively through MCTS backpropagation:
1. Only when the Solver produces a final answer that matches the consensus ground-truth, the entire chain receives positive reward.
2. This outcome-based verification implicitly validates all intermediate steps: if lower-level answers were incorrect, the Solver would likely fail to reach the correct final answer.
3. The victory count is backpropagated to all nodes in the successful chain.

The reliability of our correctness judgment is empirically validated:
1. Reward Score Distribution: Samples with reward r=1 (fully correct chains) constitute the training set and evaluation set; lower-reward samples are filtered out.
2. Fine-tuning Results: The 19.52% accuracy improvement in downstream tasks (Table 1) would be impossible if the reward signals were random or systematically biased.
3. Error Traceability: Figure 4 demonstrates that we can trace errors back to specific capability levels, confirming that the reward mechanism correctly identifies failure points.

### III.I am not clear on how is the reward of each sample used? Is it a RL reward?

**Reply**:
The reward scores are currently used for data filtering and quality control, not for reinforcement learning (RL) training directly. Below, we provide a detailed explanation of its specific purposes in our framework：

| Purpose                          | Mechanism                                                                                      | Citation in Paper                                                                                    |
| :------------------------------- | :--------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------- |
| **Data Filtering**               | Only samples with $r=1$ (62,660 complete chains) are retained for supervised fine-tuning (SFT) and evaluation. | See Section 4.1 (Line 334-339): "PyFi-600K dataset consists 603,859 samples and 62,660 sample chains with reward scores of 1. For evaluation, we proportionally sample 1,000 samples from each capability level to construct the test set across all cases. See detail in Appendix B."                             |
| **Process Supervision** | Step-wise rewards enable future training of Process Reward Models (PRMs)                       | See Section 4.3 (Line 516-521): "Providing Process Supervision, in the form of a reward score for each sample in our PyFi-600K, enables research into training reliable verifier models, known as process reward models (PRMs), to facilitate checking the correctness of each step generated by financial VLMs." |
| **Error Diagnosis**              | Reward distributions facilitate tracing model failures to specific capability levels           | Figure 4: error backtracking analysis                                                                |


### IV. According to table 1's footnote, the VLMs are fine-tuned on PyFi600K. GPT/Claude etc do not support fine-tuning. I suggest to clearly mark the models with/without fine-tuning. Moreover, I would like to see zero-shot performance across the VLMs, since it shows the capability of the FMs.

**Reply**:
We did not use our dataset to fine-tune GPT/Claude. The data presented in Table 1 represents the zero-shot performance of various models on our evaluation dataset. What we fine-tuned were Qwen2.5-VL-3B-Instruct and Qwen2.5-VL-7B-Instruct (see Section 4.2), thereby obtaining PyFi-QwenVL-3B and PyFi-QwenVL-7B (see Section 4, lines 348-352). To avoid presenting duplicate results in the main text, we only provided a performance comparison chart for the fine-tuned models (see Figure 3) to visually demonstrate the performance improvement of the fine-tuned models, and therefore did not list them again in the table. The detailed results (including with/without fine-tuning and zero-shot performance across the VLMs) are comprehensively presented in Table 13 and Table 14 (Appendix H Detailed Results).

### V.In the table 1, it compares a lot of VLMs using the proposed benchmark. However, the discussion is not enough. The performances of the VLMs vary. I would like to see why the GLM-4.5V performs significantly better, why MV1 outperforms Qwen2.5.

**Reply**:

The performance variations across VLMs in Table 1 reveal several critical insights into financial visual reasoning capabilities. GLM-4.5V achieves the highest overall accuracy (74.75%), significantly outperforming other models, which we attribute to three key factors: (1) its scalable reinforcement learning training with advanced multimodal reasoning optimization, (2) exceptional Perception capability (89.47%) that provides a robust foundation for higher-level financial analysis, and (3) strong performance across Data Extraction (78.07%) and Pattern Recognition (75.51%), indicating superior visual grounding and trend identification skills essential for financial chart interpretation.

Moonshot-V1 consistently outperforms Qwen2.5-VL across all parameter scales (e.g., MV1-128k at 54.57% vs. Qwen2.5-VL-72B at 48.84%), despite comparable model sizes. This gap stems from architectural differences: Moonshot-V1's vision preview enables superior long-context document understanding critical for multi-page financial reports, while its specialized optimization for visual document reasoning better handles the complex layouts common in financial visualizations. In contrast, Qwen2.5-VL shows particular weakness in Calculation Analysis (CA), dropping to 33.20% at 72B versus MV1's 39.06%, suggesting limitations in numerical precision and arithmetic reasoning from visual inputs.

The proprietary vs. open-source divide is pronounced: top performers GLM-4.5V, Claude-opus (64.70%), and Hunyuan-Large-Vision (59.72%) all employ extensive post-training optimization and domain adaptation unavailable in open-source checkpoints. Notably, ERNIE-4.5-turbo-vl underperforms significantly (34.47%), likely due to its training focus on Chinese-language scenarios and less emphasis on multilingual financial document analysis. These patterns demonstrate that financial visual reasoning requires specialized capabilities beyond general multimodal competence, particularly in numerical precision, long-context integration, and domain-specific pattern recognition that current open-source models have yet to fully achieve.

### VI. Missing a lot of important details in the experiments. What does the metrics PP, DE, CA, etc those metrics in Table 1 indicate? According to the table 1, the accuracy increases as the complexity level increases from 3 to 5. This is NOT aligned with the conclusion in 4.2 that as the capability level and complexity of financial image understanding increase, the accuracy of VLMs gradually declines.

**Reply**:
The metrics PP, DE, CA, PR, LR, DS represent the **six capability levels of the pyramid structure** defined in Section 3.1 (Lines 193-204): **PP (Perception)**: basic visual element recognition; **DE (Data Extraction)**: quantitative data retrieval from charts; **CA (Calculation Analysis)**: arithmetic and statistical computations; **PR (Pattern Recognition)**: trend and relationship identification; **LR (Logical Reasoning)**: causal inference and implication drawing; **DS (Decision Support)**: complex financial decision-making.

Regarding the apparent contradiction in complexity levels 3-5: this observation reflects a **nuanced interaction between capability level and complexity degree** that requires careful interpretation. The **capability level** (from PP to DS) represents the **cognitive hierarchy** of financial reasoning, while **complexity degree** (1-5) measures **intra-level difficulty variation**. Our conclusion in Section 4.2 refers to the **pyramid capability levels**, where accuracy monotonically decreases from PP (71.80% average) to DS (32.95%).

The anomalous trend (failing to show a consistent trend) in the performance of various models across different complexity degrees in Table 1 arises because each Complexity Degree mixes different Capability Levels. For example, PP (Perception) includes questions with Complexity Degrees 1-5, and DE (Data Extraction) also includes questions with Complexity Degrees 1-5. A question set corresponding to a specific Complexity Degree within the same test set may contain questions from different Capability Levels. However, when the Capability Level is strictly controlled, as the Complexity Degree increases, the questions become more challenging, and the overall accuracy of responses tends to decline.

### VII.I am not clear about the non-cot variant in the SFT L361-363. Why the final sample in the chain is used? Does the final sample mean the top layer or the lowest layer? Does this mean that the layer 2~5 is never used in SFT?

**Reply**:

The non-CoT variant uses **only the final sample in the chain**, which corresponds to the **top layer (Level 6, Decision Support)**， the most complex question requiring full pyramid reasoning. In this variant, the model is trained to directly map from image to final answer **without explicit intermediate steps**, effectively treating it as a standard supervised learning task where the model must internally perform all lower-level reasoning (Levels 1-5) implicitly.

This design creates a **deliberate ablation**: by comparing CoT-trained models (exposed to all 6 levels explicitly, see example Figure 5) against non-CoT models (only Level 6), we isolate the **value of hierarchical decomposition**. The non-CoT variant tests whether VLMs can learn the full reasoning pyramid **without structured guidance**, while the CoT variant tests whether **explicit step-wise supervision** improves performance.

Critically, **Levels 1-5 are not directly used as training targets in the non-CoT variant**. They exist only as implicit sub-tasks that the model must discover internally. This explains the performance gap: PyFi-QwenVL-3B-COT-47K achieves 40.37% versus 25.25% for the non-CoT PyFi-QwenVL-3B-47K (Table 13 in Appendix H), demonstrating that **explicit exposure to intermediate layers is essential for reliable financial reasoning**. The non-CoT model's poor performance confirms that VLMs struggle to autonomously decompose complex financial problems without hierarchical supervision, validating our pyramid design.



## Comments Suggestions And Typos:

### The presentation of the fine-tuned Qwen-VL should be improved. The color bar in the figure 3 is not clear. Missing annotations in L41

**Reply**:

The color bar in Figure 3 appears unclear due to **PDF compression artifacts during LaTeX compilation**. The original high-resolution figure uses distinct, easily distinguishable colors for different models that facilitate clear performance comparison. We will replace the compiled PDF with the original vector graphic to restore color clarity.

Additionally, **all data presented in Figure 3 is comprehensively documented in Appendix Table 13 (capability-level breakdown) and Table 14 (complexity-degree breakdown)**, where the fine-tuned Qwen-VL variants (PyFi-QwenVL-3B/7B with 500 and 47K samples, both CoT and non-CoT) are explicitly listed with numerical values for direct comparison.

Regarding Line 41's missing annotation: this was a **citation format error**. The intended reference is **Wang et al. (2024), "Math-shepherd: Verify and reinforce llms step-by-step without human annotations,"** *Proceedings of the Annual Meeting of the Association for Computational Linguistics*, pages 9426–9439. This citation supports our discussion on automated process supervision without human annotations, aligning with PyFi-adv's adversarial verification approach. We have corrected the citation format in the revised manuscript.


Confidence: 2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.
Soundness: 2 = Poor: Some of the main claims are not sufficiently supported. There are major technical/methodological problems.
Excitement: 3 = Interesting: I might mention some points of this paper to others and/or attend its presentation in a conference if there's time.
Overall Assessment: 2 = Resubmit next cycle: I think this paper needs substantial revisions that can be completed by the next ARR cycle.

Reproducibility: 2 = They would be hard pressed to reproduce the results: The contribution depends on data that are simply not available outside the author's institution or consortium and/or not enough details are provided.
Datasets: 3 = Potentially useful: Someone might find the new datasets useful for their work.
Software: 3 = Potentially useful: Someone might find the new software useful for their work.